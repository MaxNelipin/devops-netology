#1.

````shell
#Ищем долгие запросы
db.currentOp({“secs_running”: {$gte: 3}}) 

#Убиавем запрос пользователя
db.killOp(<opId>)

# Для решение нужно создать индекс, ищем то, где база начинает грузить процессор

db.custom_data.find({"application_id" : 36530,"class_name" : "Logs","UniqueId" : "a6f338db7ea728e0"}).explain('executionStats')

# И создаём индекс, но индексы лучше  создавать заранее с учётом бизнес-процессов
Id = application_id_1_class_name_1_UniqueId_1


````

#2.

в базе данных есть много ключей, срок действия которых истекает за одну секунду,
и они составляют не менее 25% от текущей совокупности ключей с установленным сроком действия ,
Redis может быть заблокированным, чтобы получить процент ключей, срок действия которых уже истек, ниже 25%.

Варианты

1. Включить активный способ очистки истёкших записей с необходимыми настройками
2. Добавить памяти или снизить TTL, чтобы всё помещалось в ОЗУ и не сбрасывалось в SWAP

#3.
Сервер не успевает отдать результаты запроса в одном соединении. Найти можно, отслеживая медленные запросы

Решение: Увеличить net_read_timeout до 60 секунд. Или бить запросы Select постранично 

#4
Заканчивается виртуальная и postgresql принудительно останавливается
Либо настраивать postgresql под железо, уменьшая лимит в  shared_buffers, work_memи hash_mem_multiplier,max_connections
либо увеличивать ОЗУ и SWAP
Либо настроить OOM killer, чтобы он был не таким агрессивным. 
